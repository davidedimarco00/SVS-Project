{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carla 03\n",
    "\n",
    "## Conda Setup\n",
    "\n",
    "Please run the following from `Anaconda Powershell Prompt` (or any other terminal with `conda` installed).\n",
    "\n",
    "From Lab PC, you can find it in the start menu or in the Desktop.\n",
    "\n",
    "### 1. Environment creation\n",
    "\n",
    "Create a new environment with the following command (you can skip this step if you already have a conda environment):\n",
    "\n",
    "```bash\n",
    "conda create -n carla-env python=3.7\n",
    "```\n",
    "\n",
    "### 2. Environment activation\n",
    "\n",
    "Activate the environment with the following command:\n",
    "\n",
    "```bash\n",
    "conda activate carla-env\n",
    "```\n",
    "\n",
    "### 3. Package installation\n",
    "\n",
    "Install the required packages with the following command (run it where the `requirements.txt` file is located):\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 4. VSCode setup\n",
    "\n",
    "If you are using VSCode, you can select the conda environment by clicking on the bottom left corner:\n",
    "\n",
    "`Select kernel > Python Environments > carla-env`\n",
    "\n",
    "Let vscode install the required packages for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "<module 'carla' from 'c:\\\\Users\\\\david\\\\anaconda3\\\\envs\\\\carla-env\\\\lib\\\\site-packages\\\\carla\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import carla, time, pygame, math, random, cv2\n",
    "import numpy as np\n",
    "\n",
    "print(carla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(10.0)\n",
    "\n",
    "world = client.get_world()\n",
    "spectator = world.get_spectator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helpful functions used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_spectator_to(transform, distance=5.0, x=0, y=0, z=4, yaw=0, pitch=-30, roll=0):\n",
    "    back_location = transform.location - transform.get_forward_vector() * distance\n",
    "    \n",
    "    back_location.x += x\n",
    "    back_location.y += y\n",
    "    back_location.z += z\n",
    "    transform.rotation.yaw += yaw\n",
    "    transform.rotation.pitch = pitch\n",
    "    transform.rotation.roll = roll\n",
    "    \n",
    "    spectator_transform = carla.Transform(back_location, transform.rotation)\n",
    "    \n",
    "    spectator.set_transform(spectator_transform)\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, pattern='vehicle.*'):\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "def draw_on_screen(world, transform, content='O', color=carla.Color(0, 255, 0), life_time=20):\n",
    "    world.debug.draw_string(transform.location, content, color=color, life_time=life_time)\n",
    "\n",
    "def spawn_camera(attach_to=None, transform=carla.Transform(carla.Location(x=1.2, z=1.2), carla.Rotation(pitch=-10)), width=640, height=600):\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', str(width))\n",
    "    camera_bp.set_attribute('image_size_y', str(height))\n",
    "    camera = world.spawn_actor(camera_bp, transform, attach_to=attach_to)\n",
    "    return camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDE suggestions\n",
    "\n",
    "In VSCode, you can get suggestions for functions and classes by pressing `Ctrl + Space`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<carla.libcarla.Map at 0x1bfba152090>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map = world.get_map()\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, carla does not provide docs for the functions and classes, so we need to install it manually.\n",
    "\n",
    "It can be done in VSCode with the following the instructions (resumed below):\n",
    "\n",
    "1. Go to the repo https://github.com/aasewold/carla-python-stubs\n",
    "2. Go to the releases section\n",
    "3. Download `*.pyi` file (i.e `__init__.pyi` and `command.pyi`)  that match carla version (e.g 0.9.15)\n",
    "4. Put the file in `./typings/carla` ([vscode reference](https://code.visualstudio.com/docs/python/settings-reference))\n",
    "\n",
    "> **Note**: `./typings/carla` should be relative to the root of the vscode project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<carla.libcarla.Map at 0x1bfba152090>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensors\n",
    "\n",
    "Sensors are another type of actors, usually spawned attached to a vehicle, designed to retrieve data from the world. The type of data depends on the sensor, but it can range from RGB images, LiDAR scans or even collision information.\n",
    "\n",
    "Sensors are divided into two main categories:\n",
    "\n",
    "- **Regular sensors**: these sensors retrieve data at a fixed rate, usually every tick (e.g RGB cameras).\n",
    "- **Trigger sensors**: these sensors only retrieve data when a certain condition is met (e.g collision sensors).\n",
    "\n",
    "Sensors details can be found in the [CARLA documentation](https://carla.readthedocs.io/en/latest/ref_sensors/).\n",
    "\n",
    "![Sensors](img/sensors.jpg)\n",
    "\n",
    "### Exploring sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor.other.collision\n",
      "sensor.camera.depth\n",
      "sensor.camera.optical_flow\n",
      "sensor.camera.normals\n",
      "sensor.other.lane_invasion\n",
      "sensor.camera.dvs\n",
      "sensor.other.imu\n",
      "sensor.other.gnss\n",
      "sensor.other.obstacle\n",
      "sensor.other.radar\n",
      "sensor.lidar.ray_cast_semantic\n",
      "sensor.lidar.ray_cast\n",
      "sensor.camera.rgb\n",
      "sensor.camera.semantic_segmentation\n",
      "sensor.other.rss\n",
      "sensor.camera.instance_segmentation\n"
     ]
    }
   ],
   "source": [
    "sensors = world.get_blueprint_library().filter('sensor.*')\n",
    "\n",
    "for sensor in sensors:\n",
    "    print(sensor.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "\n",
    "camera_bp.set_attribute('image_size_x', '640')\n",
    "camera_bp.set_attribute('image_size_y', '480')\n",
    "camera_bp.set_attribute('fov', '120')\n",
    "camera_bp.set_attribute('sensor_tick', '0')\n",
    "\n",
    "spawn_point = carla.Transform()\n",
    "camera = world.spawn_actor(camera_bp, spawn_point)\n",
    "\n",
    "time.sleep(1)\n",
    "move_spectator_to(camera.get_transform())\n",
    "\n",
    "# count = 0\n",
    "# def handle_image(image):\n",
    "#     global count\n",
    "#     image.save_to_disk(f'output/{count}.png')\n",
    "#     count += 1\n",
    "\n",
    "# camera.listen(lambda image: handle_image(image))\n",
    "\n",
    "time.sleep(10)\n",
    "camera.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spawn a vehicle and a camera in a particular position and see what the camera sees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_position = carla.Transform(carla.Location(x=-34, y=31, z=11), carla.Rotation(pitch=-18, yaw=-170, roll=0))\n",
    "\n",
    "camera = spawn_camera(transform=camera_position)\n",
    "vehicle = spawn_vehicle()\n",
    "\n",
    "camera.listen(lambda image: image.save_to_disk('C:/Users/david/OneDrive/Desktop/camera.png'))\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "camera.destroy()\n",
    "vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach a camera to a vehicle\n",
    "\n",
    "In order to acquire images from the point of view of a vehicle, we can attach a camera to it and retrieve what it sees, based on the camera's position and orientation. When the camera is attached to a vehicle, it will move with the vehicle itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle = spawn_vehicle()\n",
    "camera = spawn_camera(attach_to=vehicle)\n",
    "\n",
    "camera.listen(lambda image: image.save_to_disk(f'output/{image.frame}.png'))\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "camera.destroy()\n",
    "vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many images have been captured by the camera so far?\n",
    "\n",
    "### Live camera feed\n",
    "\n",
    "We can also visualize the camera feed in real-time. This is useful for debugging and understanding what the camera sees.\n",
    "\n",
    "We can use the `opencv` library to create a window and display the camera feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4120\\2373722164.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mrunning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mrunning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vehicle = spawn_vehicle()\n",
    "camera = spawn_camera(attach_to=vehicle)\n",
    "\n",
    "video_output = np.zeros((600, 800, 4), dtype=np.uint8)\n",
    "def camera_callback(image):\n",
    "    global video_output\n",
    "    video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "cv2.namedWindow('RGB Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "running = True\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        cv2.imshow('RGB Camera', video_output)\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.destroy()\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Multi-camera setup\n",
    "\n",
    "This exercise involves creating a multi-camera setup in the CARLA simulator to simulate a car's mirror and driver point-of-view system using four different cameras. The objective is to capture video streams from different perspectives around a vehicle, mimicking how a driver would view their surroundings through the front windshield, side mirrors, and rearview mirror. You should position each cameras with specific transformations and resolutions, and display each video in individual OpenCV windows.\n",
    "\n",
    "This is an example of output:\n",
    "\n",
    "![Multi-camera setup](img/camera-position-exercise-output.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi è verificato un arresto anomalo del Kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. \n",
      "\u001b[1;31mEsaminare il codice nelle celle per identificare una possibile causa dell'errore. \n",
      "\u001b[1;31mPer altre informazioni, fare clic<a href='https://aka.ms/vscodeJupyterKernelCrash'>qui</a>. \n",
      "\u001b[1;31mPer ulteriori dettagli, visualizzare Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "camera_transforms = [\n",
    "    (carla.Transform(carla.Location(x=1.5, z=2.4)), (640, 300)),  # Front camera\n",
    "    (carla.Transform(carla.Location(x=-0.5, y=-0.9, z=2.4), carla.Rotation(yaw=-135)), (640, 400)),  # Left side camera\n",
    "    (carla.Transform(carla.Location(x=-0.5, y=0.9, z=2.4), carla.Rotation(yaw=135)), (640, 400)),  # Right side camera\n",
    "    (carla.Transform(carla.Location(x=-1.5, z=2.4), carla.Rotation(yaw=180)), (640, 300))  # Rear camera\n",
    "]\n",
    "\n",
    "vehicle = spawn_vehicle()\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "# Spawn cameras and attach to vehicle\n",
    "cameras = []\n",
    "video_outputs = [np.zeros((640, 800, 4), dtype=np.uint8) for _ in range(4)]\n",
    "\n",
    "def create_camera_callback(index):\n",
    "    def camera_callback(image):\n",
    "        global video_outputs\n",
    "        video_outputs[index] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    return camera_callback\n",
    "\n",
    "for i, transform in enumerate(camera_transforms):\n",
    "    camera = spawn_camera(attach_to=vehicle, transform=transform[0], width=transform[1][0], height=transform[1][1])\n",
    "    camera.listen(create_camera_callback(i))\n",
    "    cameras.append(camera)\n",
    "\n",
    "cv2.namedWindow('Front Camera', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.namedWindow('Left Side Camera', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.namedWindow('Right Side Camera', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.namedWindow('Rear Camera', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "running = True\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        cv2.imshow('Front Camera', video_outputs[0])\n",
    "        cv2.imshow('Left Side Camera', video_outputs[1])\n",
    "        cv2.imshow('Right Side Camera', video_outputs[2])\n",
    "        cv2.imshow('Rear Camera', video_outputs[3])\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    for camera in cameras:\n",
    "        camera.destroy()\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Automatic light control\n",
    "\n",
    "Implement a script that allow the vehicle to turn on its lights when it gets dark and turn them off when it gets bright, using the camera sensor.\n",
    "\n",
    "To change the weather conditions, we can use the `PythonAPI\\util\\config.py` script.\n",
    "\n",
    "```bash\n",
    "python ./config.py --weather ClearNoon\n",
    "python ./config.py --weather ClearNight\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light intensity: 32.620442708333336, Elapsed time: 0.00ss\r"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mSi è verificato un arresto anomalo del Kernel durante l'esecuzione del codice nella cella attiva o in una cella precedente. \n",
      "\u001b[1;31mEsaminare il codice nelle celle per identificare una possibile causa dell'errore. \n",
      "\u001b[1;31mPer altre informazioni, fare clic<a href='https://aka.ms/vscodeJupyterKernelCrash'>qui</a>. \n",
      "\u001b[1;31mPer ulteriori dettagli, visualizzare Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "\n",
    "vehicle = spawn_vehicle(pattern='vehicle.mercedes.coupe_2020')\n",
    "camera = spawn_camera(attach_to=vehicle)\n",
    "\n",
    "\n",
    "video_output = np.zeros((600, 800, 4), dtype=np.uint8)\n",
    "def camera_callback(image):\n",
    "    global video_output\n",
    "    video_output = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "\n",
    "camera.listen(lambda image: camera_callback(image))\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "cv2.namedWindow('Automatic light control', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "running = True\n",
    "\n",
    "# ============ Day/Night Classification ============ #\n",
    "\n",
    "is_night = False\n",
    "start_time = time.time()\n",
    "brightness_threshold = 50\n",
    "time_threshold = 5\n",
    "\n",
    "def is_night_image_classifier(image):\n",
    "    global is_night, start_time, brightness_threshold, time_threshold\n",
    "    \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "    light_intensity = np.mean(gray_image)\n",
    "\n",
    "    current_time = time.time()\n",
    "    if (light_intensity > brightness_threshold and not is_night) or (light_intensity < brightness_threshold and is_night):\n",
    "        start_time = time.time()\n",
    "\n",
    "    elapsed_time = current_time - start_time\n",
    "    print(f'Light intensity: {light_intensity}, Elapsed time: {elapsed_time:.2f}s', end='\\r')\n",
    "    \n",
    "    if elapsed_time >= time_threshold:\n",
    "        is_night = not is_night\n",
    "\n",
    "    return is_night\n",
    "\n",
    "# ============ Day/Night Classification ============ #\n",
    "\n",
    "try:\n",
    "    while running:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            running = False\n",
    "            break\n",
    "        cv2.imshow('Automatic light control', video_output)\n",
    "        \n",
    "        move_spectator_to(vehicle.get_transform(), distance=-10.0, z=2.0, pitch=0, yaw=180)\n",
    "        \n",
    "        if is_night_image_classifier(video_output):\n",
    "            vehicle.set_light_state(carla.VehicleLightState(carla.VehicleLightState.HighBeam))\n",
    "        else:\n",
    "            vehicle.set_light_state(carla.VehicleLightState(carla.VehicleLightState.NONE))\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n",
    "    camera.destroy()\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vehicle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21712\\921876088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvehicle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vehicle' is not defined"
     ]
    }
   ],
   "source": [
    "vehicle.destroy()\n",
    "camera.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 - Pacman effect using GPS\n",
    "\n",
    "Implement the Pacman effect for a vehicle using a GPS sensor for tracking the vehicle's position. You can start from the implementation of the pacman effect using the vehicle's position below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = spawn_vehicle(world)\n",
    "\n",
    "ROAD_X_MIN = -110\n",
    "ROAD_X_MAX = 110\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        transform = vehicle.get_transform()\n",
    "        location = transform.location\n",
    "\n",
    "        print(f\"Location: {location.x}, {location.y}\", end='\\r')\n",
    "\n",
    "        if location.x > ROAD_X_MAX:\n",
    "            location.x = ROAD_X_MIN\n",
    "            vehicle.set_transform(carla.Transform(location, transform.rotation))\n",
    "\n",
    "        control = carla.VehicleControl(throttle=0.5)\n",
    "        vehicle.apply_control(control)\n",
    "\n",
    "        world.tick()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = spawn_vehicle()\n",
    "\n",
    "gps_blueprint = world.get_blueprint_library().find('sensor.other.gnss')\n",
    "gps_sensor = world.spawn_actor(gps_blueprint, carla.Transform(), attach_to=vehicle)\n",
    "\n",
    "ROAD_X_MIN = -110\n",
    "LONGITUDE_MAX = 0.001\n",
    "\n",
    "latest_gps = {\"latitude\": 0.0, \"longitude\": 0.0}\n",
    "\n",
    "def gps_callback(gps_data):\n",
    "    global latest_gps\n",
    "    latest_gps[\"latitude\"] = gps_data.latitude\n",
    "    latest_gps[\"longitude\"] = gps_data.longitude\n",
    "\n",
    "gps_sensor.listen(gps_callback)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        current_x = latest_gps[\"longitude\"]\n",
    "        print(f\"Longitude: {current_x}\", end='\\r')\n",
    "\n",
    "        if current_x > LONGITUDE_MAX:\n",
    "            new_location = carla.Location(x=ROAD_X_MIN, y=vehicle.get_transform().location.y)\n",
    "            vehicle.set_transform(carla.Transform(new_location, vehicle.get_transform().rotation))\n",
    "\n",
    "        control = carla.VehicleControl(throttle=0.5)\n",
    "        vehicle.apply_control(control)\n",
    "\n",
    "        world.tick()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    gps_sensor.destroy()\n",
    "    vehicle.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Emergency braking system using LIDAR\n",
    "\n",
    "LIDAR (Light Detection and Ranging) is a method for determining ranges by targeting an object or a surface with a laser and measuring the time for the reflected light to return to the receiver.\n",
    "\n",
    "LIDAR sensors are used in autonomous vehicles to detect obstacles and create a 3D representation of the environment.\n",
    "\n",
    "Implment a script that detect obstacles in front of the vehicle and apply the brakes if the distance is less than a threshold, using the LIDAR sensor.\n",
    "\n",
    "Some notes on the simulation environment to test the emergency braking system:\n",
    "\n",
    "- Spawn a vehicle (i.e ego vehicle)\n",
    "- Spawn a vehicle (i.e target vehicle) an position it in front of the ego vehicle\n",
    "- Attach a LIDAR sensor to the ego vehicle\n",
    "- Create the logic to detect obstacles in front of the ego vehicle, based on the LIDAR sensor data. You can find the documentation for the LIDAR sensor [here](https://carla.readthedocs.io/en/latest/ref_sensors/#lidar-sensor).\n",
    "- Apply the brakes if the distance is less than a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13044\\2287649539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Spawn target vehicle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtarget_vehicle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspawn_vehicle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_offset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13044\\2287649539.py\u001b[0m in \u001b[0;36mspawn_vehicle\u001b[1;34m(vehicle_index, spawn_index, x_offset, y_offset, pattern)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspawn_vehicle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvehicle_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspawn_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'vehicle.*model3*'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mcarla\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVehicle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mblueprint_library\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_blueprint_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mvehicle_bp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblueprint_library\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvehicle_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: time-out of 10000ms while waiting for the simulator, make sure the simulator is ready and connected to localhost:2000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def spawn_vehicle(vehicle_index=0, spawn_index=0, x_offset=0, y_offset=0, pattern='vehicle.*model3*') -> carla.Vehicle:\n",
    "    blueprint_library = world.get_blueprint_library()\n",
    "    vehicle_bp = blueprint_library.filter(pattern)[vehicle_index]\n",
    "    spawn_point = world.get_map().get_spawn_points()[spawn_index]\n",
    "    spawn_point.location.x += x_offset\n",
    "    spawn_point.location.y += y_offset\n",
    "    vehicle = world.spawn_actor(vehicle_bp, spawn_point)\n",
    "    return vehicle\n",
    "\n",
    "# Spawn target vehicle\n",
    "target_vehicle = spawn_vehicle(x_offset=50)\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "# Spawn the vehicle\n",
    "ego_vehicle = spawn_vehicle()\n",
    "\n",
    "# Add the radar sensor\n",
    "radar_bp = world.get_blueprint_library().find('sensor.other.radar')\n",
    "radar_bp.set_attribute('horizontal_fov', '10')  # Horizontal field of view\n",
    "radar_bp.set_attribute('vertical_fov', '10')    # Vertical field of view\n",
    "radar_bp.set_attribute('range', '20')           # Maximum range\n",
    "\n",
    "radar_transform = carla.Transform(carla.Location(x=2.0, z=1.0))\n",
    "radar = world.spawn_actor(radar_bp, radar_transform, attach_to=ego_vehicle)\n",
    "\n",
    "# Variable to store the minimum TTC\n",
    "min_ttc = float('inf')\n",
    "\n",
    "def radar_callback(data: carla.RadarMeasurement):\n",
    "    global min_ttc, min_distance\n",
    "    min_ttc = float('inf')\n",
    "\n",
    "    for detection, i in zip(data, range(len(data))):\n",
    "        absolute_speed = abs(detection.velocity)\n",
    "\n",
    "        # Calculate TTC\n",
    "        if absolute_speed != 0:\n",
    "            ttc = detection.depth / absolute_speed\n",
    "            if ttc < min_ttc:\n",
    "                min_ttc = ttc\n",
    "\n",
    "# Register the radar callback\n",
    "radar.listen(radar_callback)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # TTC threshold (e.g., 2 seconds)\n",
    "        ttc_threshold = 2.0\n",
    "\n",
    "        # Braking control\n",
    "        if min_ttc < ttc_threshold:\n",
    "            control = carla.VehicleControl()\n",
    "            control.brake = 1.0  # Maximum braking\n",
    "            ego_vehicle.apply_control(control)\n",
    "            print(\"Emergency braking activated!\")\n",
    "        else:\n",
    "            control = carla.VehicleControl()\n",
    "            control.throttle = 0.5  # Maintain constant speed\n",
    "            ego_vehicle.apply_control(control)\n",
    "        \n",
    "        time.sleep(0.05)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Keyboard interrupt detected.\")\n",
    "\n",
    "finally:\n",
    "    radar.stop()\n",
    "    radar.destroy()\n",
    "    ego_vehicle.destroy()\n",
    "    target_vehicle.destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud point: LidarMeasurement(frame=5781, timestamp=424.827833, number_of_points=426)\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lidar.destroy()\n",
    "ego_vehicle.destroy()\n",
    "target_vehicle.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
